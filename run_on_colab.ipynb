{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Deep Temporal Transformer for Financial Fraud Detection\n",
                "**Author:** Prasad Kharat  \n",
                "**GPU Optimized** - Works on any GPU (T4, V100, A100)\n",
                "\n",
                "This notebook demonstrates the complete fraud detection pipeline."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU availability\n",
                "!nvidia-smi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install torch torchvision scikit-learn pandas matplotlib seaborn -q\n",
                "print(\"âœ… Dependencies installed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Upload Your Code\n",
                "\n",
                "**Option A:** Upload the entire project folder as a zip file, then unzip it.\n",
                "\n",
                "**Option B:** Clone from GitHub (if you've pushed it):\n",
                "```python\n",
                "!git clone https://github.com/yourusername/Deep-Temporal-Transformer.git\n",
                "%cd Deep-Temporal-Transformer-For-High-Financial-Fraud-Detection\n",
                "```\n",
                "\n",
                "**Option C:** Use the file upload below:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Option C: Upload zip file\n",
                "from google.colab import files\n",
                "import zipfile\n",
                "\n",
                "print(\"Upload your project zip file:\")\n",
                "uploaded = files.upload()\n",
                "\n",
                "# Unzip\n",
                "for filename in uploaded.keys():\n",
                "    if filename.endswith('.zip'):\n",
                "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
                "            zip_ref.extractall('.')\n",
                "        print(f\"âœ… Extracted {filename}\")\n",
                "\n",
                "# Navigate to directory\n",
                "%cd Deep-Temporal-Transformer-For-High-Financial-Fraud-Detection"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Install the Package"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install the package in development mode\n",
                "!pip install -e . -q\n",
                "print(\"âœ… Package installed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Quick Demo - Basic Usage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from deep_temporal_transformer import (\n",
                "    get_default_config, DataProcessor, ModelTrainer,\n",
                "    set_random_seeds, get_device\n",
                ")\n",
                "\n",
                "# Setup\n",
                "set_random_seeds(42)\n",
                "config = get_default_config()\n",
                "device = get_device()\n",
                "\n",
                "print(f\"ðŸš€ Using device: {device}\")\n",
                "print(f\"ðŸ“Š Model config: d_model={config.model.d_model}, layers={config.model.num_layers}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load and process data (using synthetic data for demo)\n",
                "processor = DataProcessor(seq_len=8, random_state=42)\n",
                "X_train, y_train, X_val, y_val, X_test, y_test = processor.process_data()\n",
                "\n",
                "print(f\"âœ… Data loaded:\")\n",
                "print(f\"  Train: {X_train.shape}\")\n",
                "print(f\"  Val: {X_val.shape}\")\n",
                "print(f\"  Test: {X_test.shape}\")\n",
                "print(f\"  Fraud rate: {y_train.mean():.2%}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train model (adjust epochs for quick demo)\n",
                "config.training.epochs = 10  # Reduce for quick demo\n",
                "config.training.batch_size = 256\n",
                "\n",
                "trainer = ModelTrainer(config, device)\n",
                "trainer.setup_model(input_dim=X_train.shape[-1])\n",
                "\n",
                "print(f\"ðŸ§  Model initialized with {sum(p.numel() for p in trainer.model.parameters()):,} parameters\")\n",
                "print(\"\\nðŸŽ¯ Starting training...\")\n",
                "\n",
                "history = trainer.train(X_train, y_train, X_val, y_val)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate on test set\n",
                "results = trainer.evaluate_model(X_test, y_test)\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"ðŸ“Š TEST SET RESULTS\")\n",
                "print(\"=\"*60)\n",
                "print(f\"F1 Score:       {results['f1']:.4f}\")\n",
                "print(f\"AUC Score:      {results['auc']:.4f}\")\n",
                "print(f\"Precision:      {results['precision']:.4f}\")\n",
                "print(f\"Recall:         {results['recall']:.4f}\")\n",
                "print(f\"Inference Time: {results['avg_inference_time']:.6f}s per transaction\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Advanced Usage - GPU-Optimized Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from deep_temporal_transformer.models.advanced_transformer import DeepTemporalTransformerAdvanced\n",
                "from deep_temporal_transformer.training.advanced_training import (\n",
                "    detect_and_configure_gpu, FocalLossAdvanced\n",
                ")\n",
                "\n",
                "# Auto-detect and configure GPU\n",
                "gpu_config = detect_and_configure_gpu()\n",
                "device = gpu_config['device']\n",
                "\n",
                "print(\"\\nðŸš€ GPU Configuration:\")\n",
                "print(f\"  GPU: {gpu_config['gpu_name']}\")\n",
                "print(f\"  Memory: {gpu_config['gpu_memory_gb']:.1f} GB\")\n",
                "print(f\"  Mixed Precision: {'BF16' if gpu_config['use_bf16'] else ('FP16' if gpu_config['use_fp16'] else 'FP32')}\")\n",
                "print(f\"  Batch Size Multiplier: {gpu_config['batch_size_multiplier']:.1f}x\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize advanced model with all innovations\n",
                "model = DeepTemporalTransformerAdvanced(\n",
                "    input_dim=X_train.shape[-1],\n",
                "    d_model=256,\n",
                "    num_heads=8,\n",
                "    num_layers=6,\n",
                "    num_experts=8,\n",
                "    memory_slots=512,\n",
                "    use_gradient_checkpointing=True  # Enable for memory efficiency\n",
                ").to(device)\n",
                "\n",
                "print(f\"\\nðŸ§  Advanced Model Initialized\")\n",
                "print(f\"  Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
                "print(f\"  Features: Sparse Attention + MoE + Temporal Modules + External Memory\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example: Predict with uncertainty estimation\n",
                "import torch\n",
                "\n",
                "# Convert test data to tensor\n",
                "X_test_tensor = torch.FloatTensor(X_test[:100]).to(device)\n",
                "\n",
                "# Get predictions with uncertainty\n",
                "mean_probs, uncertainty = model.predict_with_uncertainty(X_test_tensor, n_samples=10)\n",
                "\n",
                "print(\"\\nðŸŽ¯ Uncertainty-Aware Predictions (first 5):\")\n",
                "for i in range(5):\n",
                "    print(f\"  Sample {i+1}: Fraud Prob={mean_probs[i]:.4f}, Uncertainty={uncertainty[i]:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Visualizations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from deep_temporal_transformer.evaluation.explain import ModelExplainer\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Create explainer\n",
                "explainer = ModelExplainer(trainer.model, device)\n",
                "\n",
                "# Plot training history\n",
                "explainer.plot_training_history(history)\n",
                "plt.show()\n",
                "\n",
                "# Plot confusion matrix\n",
                "explainer.plot_confusion_matrix(X_test, y_test)\n",
                "plt.show()\n",
                "\n",
                "print(\"âœ… Visualizations complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Save Model (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save to Google Drive (optional)\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# Save model\n",
                "save_path = '/content/drive/MyDrive/fraud_detection_model.pt'\n",
                "trainer.save_model(save_path)\n",
                "print(f\"âœ… Model saved to: {save_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸŽ‰ Complete!\n",
                "\n",
                "You've successfully:\n",
                "- âœ… Set up the environment\n",
                "- âœ… Trained the Deep Temporal Transformer\n",
                "- âœ… Evaluated performance\n",
                "- âœ… Explored advanced features\n",
                "- âœ… Generated visualizations\n",
                "\n",
                "**Next Steps:**\n",
                "- Use your own dataset instead of synthetic data\n",
                "- Experiment with hyperparameters\n",
                "- Try the advanced model with uncertainty estimation\n",
                "- Generate thesis plots and results"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.0"
        },
        "accelerator": "GPU"
    },
    "nbformat": 4,
    "nbformat_minor": 0
}