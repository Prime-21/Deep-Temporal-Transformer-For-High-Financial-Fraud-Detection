{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Deep Temporal Transformer for Financial Fraud Detection\n",
                "**Author:** Prasad Kharat  \n",
                "**GPU Optimized** - Works on any GPU (T4, V100, A100)\n",
                "\n",
                "This notebook demonstrates the complete fraud detection pipeline."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "/bin/bash: line 1: nvidia-smi: command not found\n"
                    ]
                }
            ],
            "source": [
                "# Check GPU availability\n",
                "!nvidia-smi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… Dependencies installed!\n"
                    ]
                }
            ],
            "source": [
                "# Install dependencies\n",
                "!pip install torch torchvision scikit-learn pandas matplotlib seaborn -q\n",
                "print(\"âœ… Dependencies installed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Upload Your Code\n",
                "\n",
                "**Option A:** Upload the entire project folder as a zip file, then unzip it.\n",
                "\n",
                "**Option B:** Clone from GitHub (if you've pushed it):\n",
                "```python\n",
                "!git clone https://github.com/Prime-21/Deep-Temporal-Transformer-For-High-Financial-Fraud-Detection.git\n",
                "%cd Deep-Temporal-Transformer-For-High-Financial-Fraud-Detection\n",
                "```\n",
                "\n",
                "**Option C:** Use the file upload below:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Cloning into 'Deep-Temporal-Transformer-For-High-Financial-Fraud-Detection'...\n",
                        "remote: Enumerating objects: 89, done.\u001b[K\n",
                        "remote: Counting objects: 100% (89/89), done.\u001b[K\n",
                        "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
                        "remote: Total 89 (delta 22), reused 53 (delta 15), pack-reused 0 (from 0)\u001b[K\n",
                        "Receiving objects: 100% (89/89), 89.28 KiB | 3.19 MiB/s, done.\n",
                        "Resolving deltas: 100% (22/22), done.\n",
                        "/content/Deep-Temporal-Transformer-For-High-Financial-Fraud-Detection/Deep-Temporal-Transformer-For-High-Financial-Fraud-Detection\n"
                    ]
                }
            ],
            "source": [
                "!git clone https://github.com/Prime-21/Deep-Temporal-Transformer-For-High-Financial-Fraud-Detection.git\n",
                "%cd Deep-Temporal-Transformer-For-High-Financial-Fraud-Detection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Upload your project zip file:\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "     <input type=\"file\" id=\"files-6d5e9564-1b91-41eb-9486-bf443798ae7d\" name=\"files[]\" multiple disabled\n",
                            "        style=\"border:none\" />\n",
                            "     <output id=\"result-6d5e9564-1b91-41eb-9486-bf443798ae7d\">\n",
                            "      Upload widget is only available when the cell has been executed in the\n",
                            "      current browser session. Please rerun this cell to enable.\n",
                            "      </output>\n",
                            "      <script>// Copyright 2017 Google LLC\n",
                            "//\n",
                            "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
                            "// you may not use this file except in compliance with the License.\n",
                            "// You may obtain a copy of the License at\n",
                            "//\n",
                            "//      http://www.apache.org/licenses/LICENSE-2.0\n",
                            "//\n",
                            "// Unless required by applicable law or agreed to in writing, software\n",
                            "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
                            "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
                            "// See the License for the specific language governing permissions and\n",
                            "// limitations under the License.\n",
                            "\n",
                            "/**\n",
                            " * @fileoverview Helpers for google.colab Python module.\n",
                            " */\n",
                            "(function(scope) {\n",
                            "function span(text, styleAttributes = {}) {\n",
                            "  const element = document.createElement('span');\n",
                            "  element.textContent = text;\n",
                            "  for (const key of Object.keys(styleAttributes)) {\n",
                            "    element.style[key] = styleAttributes[key];\n",
                            "  }\n",
                            "  return element;\n",
                            "}\n",
                            "\n",
                            "// Max number of bytes which will be uploaded at a time.\n",
                            "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
                            "\n",
                            "function _uploadFiles(inputId, outputId) {\n",
                            "  const steps = uploadFilesStep(inputId, outputId);\n",
                            "  const outputElement = document.getElementById(outputId);\n",
                            "  // Cache steps on the outputElement to make it available for the next call\n",
                            "  // to uploadFilesContinue from Python.\n",
                            "  outputElement.steps = steps;\n",
                            "\n",
                            "  return _uploadFilesContinue(outputId);\n",
                            "}\n",
                            "\n",
                            "// This is roughly an async generator (not supported in the browser yet),\n",
                            "// where there are multiple asynchronous steps and the Python side is going\n",
                            "// to poll for completion of each step.\n",
                            "// This uses a Promise to block the python side on completion of each step,\n",
                            "// then passes the result of the previous step as the input to the next step.\n",
                            "function _uploadFilesContinue(outputId) {\n",
                            "  const outputElement = document.getElementById(outputId);\n",
                            "  const steps = outputElement.steps;\n",
                            "\n",
                            "  const next = steps.next(outputElement.lastPromiseValue);\n",
                            "  return Promise.resolve(next.value.promise).then((value) => {\n",
                            "    // Cache the last promise value to make it available to the next\n",
                            "    // step of the generator.\n",
                            "    outputElement.lastPromiseValue = value;\n",
                            "    return next.value.response;\n",
                            "  });\n",
                            "}\n",
                            "\n",
                            "/**\n",
                            " * Generator function which is called between each async step of the upload\n",
                            " * process.\n",
                            " * @param {string} inputId Element ID of the input file picker element.\n",
                            " * @param {string} outputId Element ID of the output display.\n",
                            " * @return {!Iterable<!Object>} Iterable of next steps.\n",
                            " */\n",
                            "function* uploadFilesStep(inputId, outputId) {\n",
                            "  const inputElement = document.getElementById(inputId);\n",
                            "  inputElement.disabled = false;\n",
                            "\n",
                            "  const outputElement = document.getElementById(outputId);\n",
                            "  outputElement.innerHTML = '';\n",
                            "\n",
                            "  const pickedPromise = new Promise((resolve) => {\n",
                            "    inputElement.addEventListener('change', (e) => {\n",
                            "      resolve(e.target.files);\n",
                            "    });\n",
                            "  });\n",
                            "\n",
                            "  const cancel = document.createElement('button');\n",
                            "  inputElement.parentElement.appendChild(cancel);\n",
                            "  cancel.textContent = 'Cancel upload';\n",
                            "  const cancelPromise = new Promise((resolve) => {\n",
                            "    cancel.onclick = () => {\n",
                            "      resolve(null);\n",
                            "    };\n",
                            "  });\n",
                            "\n",
                            "  // Wait for the user to pick the files.\n",
                            "  const files = yield {\n",
                            "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
                            "    response: {\n",
                            "      action: 'starting',\n",
                            "    }\n",
                            "  };\n",
                            "\n",
                            "  cancel.remove();\n",
                            "\n",
                            "  // Disable the input element since further picks are not allowed.\n",
                            "  inputElement.disabled = true;\n",
                            "\n",
                            "  if (!files) {\n",
                            "    return {\n",
                            "      response: {\n",
                            "        action: 'complete',\n",
                            "      }\n",
                            "    };\n",
                            "  }\n",
                            "\n",
                            "  for (const file of files) {\n",
                            "    const li = document.createElement('li');\n",
                            "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
                            "    li.append(span(\n",
                            "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
                            "        `last modified: ${\n",
                            "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
                            "                                    'n/a'} - `));\n",
                            "    const percent = span('0% done');\n",
                            "    li.appendChild(percent);\n",
                            "\n",
                            "    outputElement.appendChild(li);\n",
                            "\n",
                            "    const fileDataPromise = new Promise((resolve) => {\n",
                            "      const reader = new FileReader();\n",
                            "      reader.onload = (e) => {\n",
                            "        resolve(e.target.result);\n",
                            "      };\n",
                            "      reader.readAsArrayBuffer(file);\n",
                            "    });\n",
                            "    // Wait for the data to be ready.\n",
                            "    let fileData = yield {\n",
                            "      promise: fileDataPromise,\n",
                            "      response: {\n",
                            "        action: 'continue',\n",
                            "      }\n",
                            "    };\n",
                            "\n",
                            "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
                            "    let position = 0;\n",
                            "    do {\n",
                            "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
                            "      const chunk = new Uint8Array(fileData, position, length);\n",
                            "      position += length;\n",
                            "\n",
                            "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
                            "      yield {\n",
                            "        response: {\n",
                            "          action: 'append',\n",
                            "          file: file.name,\n",
                            "          data: base64,\n",
                            "        },\n",
                            "      };\n",
                            "\n",
                            "      let percentDone = fileData.byteLength === 0 ?\n",
                            "          100 :\n",
                            "          Math.round((position / fileData.byteLength) * 100);\n",
                            "      percent.textContent = `${percentDone}% done`;\n",
                            "\n",
                            "    } while (position < fileData.byteLength);\n",
                            "  }\n",
                            "\n",
                            "  // All done.\n",
                            "  yield {\n",
                            "    response: {\n",
                            "      action: 'complete',\n",
                            "    }\n",
                            "  };\n",
                            "}\n",
                            "\n",
                            "scope.google = scope.google || {};\n",
                            "scope.google.colab = scope.google.colab || {};\n",
                            "scope.google.colab._files = {\n",
                            "  _uploadFiles,\n",
                            "  _uploadFilesContinue,\n",
                            "};\n",
                            "})(self);\n",
                            "</script> "
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipython-input-3726085928.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Upload your project zip file:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Unzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "# Option C: Upload zip file\n",
                "from google.colab import files\n",
                "import zipfile\n",
                "\n",
                "print(\"Upload your project zip file:\")\n",
                "uploaded = files.upload()\n",
                "\n",
                "# Unzip\n",
                "for filename in uploaded.keys():\n",
                "    if filename.endswith('.zip'):\n",
                "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
                "            zip_ref.extractall('.')\n",
                "        print(f\"âœ… Extracted {filename}\")\n",
                "\n",
                "# Navigate to directory\n",
                "%cd Deep-Temporal-Transformer-For-High-Financial-Fraud-Detection"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Install the Package"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
                        "âœ… Package installed!\n"
                    ]
                }
            ],
            "source": [
                "# Install the package in development mode\n",
                "!pip install -e . -q\n",
                "print(\"âœ… Package installed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Quick Demo - Basic Usage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'deep_temporal_transformer.models.model'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipython-input-3457725423.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from deep_temporal_transformer import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mget_default_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataProcessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelTrainer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mset_random_seeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/content/Deep-Temporal-Transformer-For-High-Financial-Fraud-Detection/deep_temporal_transformer/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeep_temporal_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_default_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeep_temporal_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvanced_transformer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeepTemporalTransformerAdvanced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeep_temporal_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_enhanced\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeepTemporalTransformerEnhanced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFocalLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeep_temporal_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/content/Deep-Temporal-Transformer-For-High-Financial-Fraud-Detection/deep_temporal_transformer/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"Model implementations.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeep_temporal_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeepTemporalTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFocalLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeep_temporal_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaseline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaselineModels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'DeepTemporalTransformer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FocalLoss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BaselineModels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deep_temporal_transformer.models.model'",
                        "",
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "from deep_temporal_transformer import (\n",
                "    get_default_config, DataProcessor, ModelTrainer,\n",
                "    set_random_seeds, get_device\n",
                ")\n",
                "\n",
                "# Setup\n",
                "set_random_seeds(42)\n",
                "config = get_default_config()\n",
                "device = get_device()\n",
                "\n",
                "print(f\"ðŸš€ Using device: {device}\")\n",
                "print(f\"ðŸ“Š Model config: d_model={config.model.d_model}, layers={config.model.num_layers}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load and process data (using synthetic data for demo)\n",
                "processor = DataProcessor(seq_len=8, random_state=42)\n",
                "X_train, y_train, X_val, y_val, X_test, y_test = processor.process_data()\n",
                "\n",
                "print(f\"âœ… Data loaded:\")\n",
                "print(f\"  Train: {X_train.shape}\")\n",
                "print(f\"  Val: {X_val.shape}\")\n",
                "print(f\"  Test: {X_test.shape}\")\n",
                "print(f\"  Fraud rate: {y_train.mean():.2%}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train model (adjust epochs for quick demo)\n",
                "config.training.epochs = 10  # Reduce for quick demo\n",
                "config.training.batch_size = 256\n",
                "\n",
                "trainer = ModelTrainer(config, device)\n",
                "trainer.setup_model(input_dim=X_train.shape[-1])\n",
                "\n",
                "print(f\"ðŸ§  Model initialized with {sum(p.numel() for p in trainer.model.parameters()):,} parameters\")\n",
                "print(\"\\nðŸŽ¯ Starting training...\")\n",
                "\n",
                "history = trainer.train(X_train, y_train, X_val, y_val)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate on test set\n",
                "results = trainer.evaluate_model(X_test, y_test)\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"ðŸ“Š TEST SET RESULTS\")\n",
                "print(\"=\"*60)\n",
                "print(f\"F1 Score:       {results['f1']:.4f}\")\n",
                "print(f\"AUC Score:      {results['auc']:.4f}\")\n",
                "print(f\"Precision:      {results['precision']:.4f}\")\n",
                "print(f\"Recall:         {results['recall']:.4f}\")\n",
                "print(f\"Inference Time: {results['avg_inference_time']:.6f}s per transaction\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Advanced Usage - GPU-Optimized Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from deep_temporal_transformer.models.advanced_transformer import DeepTemporalTransformerAdvanced\n",
                "from deep_temporal_transformer.training.advanced_training import (\n",
                "    detect_and_configure_gpu, FocalLossAdvanced\n",
                ")\n",
                "\n",
                "# Auto-detect and configure GPU\n",
                "gpu_config = detect_and_configure_gpu()\n",
                "device = gpu_config['device']\n",
                "\n",
                "print(\"\\nðŸš€ GPU Configuration:\")\n",
                "print(f\"  GPU: {gpu_config['gpu_name']}\")\n",
                "print(f\"  Memory: {gpu_config['gpu_memory_gb']:.1f} GB\")\n",
                "print(f\"  Mixed Precision: {'BF16' if gpu_config['use_bf16'] else ('FP16' if gpu_config['use_fp16'] else 'FP32')}\")\n",
                "print(f\"  Batch Size Multiplier: {gpu_config['batch_size_multiplier']:.1f}x\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize advanced model with all innovations\n",
                "model = DeepTemporalTransformerAdvanced(\n",
                "    input_dim=X_train.shape[-1],\n",
                "    d_model=256,\n",
                "    num_heads=8,\n",
                "    num_layers=6,\n",
                "    num_experts=8,\n",
                "    memory_slots=512,\n",
                "    use_gradient_checkpointing=True  # Enable for memory efficiency\n",
                ").to(device)\n",
                "\n",
                "print(f\"\\nðŸ§  Advanced Model Initialized\")\n",
                "print(f\"  Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
                "print(f\"  Features: Sparse Attention + MoE + Temporal Modules + External Memory\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example: Predict with uncertainty estimation\n",
                "import torch\n",
                "\n",
                "# Convert test data to tensor\n",
                "X_test_tensor = torch.FloatTensor(X_test[:100]).to(device)\n",
                "\n",
                "# Get predictions with uncertainty\n",
                "mean_probs, uncertainty = model.predict_with_uncertainty(X_test_tensor, n_samples=10)\n",
                "\n",
                "print(\"\\nðŸŽ¯ Uncertainty-Aware Predictions (first 5):\")\n",
                "for i in range(5):\n",
                "    print(f\"  Sample {i+1}: Fraud Prob={mean_probs[i]:.4f}, Uncertainty={uncertainty[i]:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Visualizations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from deep_temporal_transformer.evaluation.explain import ModelExplainer\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Create explainer\n",
                "explainer = ModelExplainer(trainer.model, device)\n",
                "\n",
                "# Plot training history\n",
                "explainer.plot_training_history(history)\n",
                "plt.show()\n",
                "\n",
                "# Plot confusion matrix\n",
                "explainer.plot_confusion_matrix(X_test, y_test)\n",
                "plt.show()\n",
                "\n",
                "print(\"âœ… Visualizations complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Save Model (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save to Google Drive (optional)\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# Save model\n",
                "save_path = '/content/drive/MyDrive/fraud_detection_model.pt'\n",
                "trainer.save_model(save_path)\n",
                "print(f\"âœ… Model saved to: {save_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸŽ‰ Complete!\n",
                "\n",
                "You've successfully:\n",
                "- âœ… Set up the environment\n",
                "- âœ… Trained the Deep Temporal Transformer\n",
                "- âœ… Evaluated performance\n",
                "- âœ… Explored advanced features\n",
                "- âœ… Generated visualizations\n",
                "\n",
                "**Next Steps:**\n",
                "- Use your own dataset instead of synthetic data\n",
                "- Experiment with hyperparameters\n",
                "- Try the advanced model with uncertainty estimation\n",
                "- Generate thesis plots and results"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
